# active-learning-proj

Recent surges in the quantity and variety of data lead
to a constant search to find techniques that optimize
the process of training machine learning classifiers.
The cases where there are a lot of unlabelled data
and the cost of annotating is not insignificant are par-
ticularly meaningful. Because of this, there has been
progress in the area of active learning, which is related
to minimizing the cost (computational and otherwise)
of sample annotation. Additionally, the ever-growing
spread of machine learning to real-life cases makes it
important to steer away from static (closed-set) mod-
els and move into dynamic (open-set) models, which
do not limit the classifier to a fixed number of classes.
Since these are 2 heavily researched areas, it is perti-
nent to seek different querying metrics to optimize the
performance of such classification algorithms. On this
paper, we present a continuation of past research on
the usage of unknown interest as described in Macedo
et al. (2011) [1] to bring insight into the comparison
of the performance of several querying metrics.
